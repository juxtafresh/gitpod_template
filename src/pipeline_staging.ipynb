{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen Niche List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "# need to modify this to recursivly parse the outputs down the json tree\n",
    "\n",
    "\n",
    "def gen_niche_list():\n",
    "    pytrends = TrendReq(hl='en-US')\n",
    "    json_response = pytrends.categories()\n",
    "    data = json_response['children']\n",
    "    prefix = 'metadata_'\n",
    "    df = pd.json_normalize(\n",
    "        data, 'children', ['name', 'id'], record_prefix=prefix)\n",
    "    metadata_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    df = pd.concat(\n",
    "        [df[['name', 'id']], df[metadata_cols].apply(pd.Series)], axis=1)\n",
    "    df = df.explode(\"metadata_children\").reset_index(drop=True)\n",
    "    df = pd.concat([df.drop([\"metadata_children\"], axis=1),\n",
    "                   df[\"metadata_children\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Remove completely NaN columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Column cleaning operations\n",
    "\n",
    "    columns = df.columns.tolist()\n",
    "\n",
    "    # Rename first \"name\" column to \"parent_category\"\n",
    "    columns[0] = 'parent_cat_desc'\n",
    "    columns[1] = 'parent_cat_id'\n",
    "\n",
    "    df.columns = columns\n",
    "\n",
    "    # Column dtype setting\n",
    "\n",
    "    df['id'] = df['id'].astype('Int64')\n",
    "\n",
    "    # Explode the final childrens column\n",
    "\n",
    "    df = df.explode(\"children\").reset_index(drop=True)\n",
    "    df = pd.concat([df.drop([\"children\"], axis=1),\n",
    "                   df[\"children\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Remove completely NaN columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Column cleaning operations part 2 lol\n",
    "\n",
    "    columns_2 = df.columns.tolist()\n",
    "\n",
    "    # Rename first \"name\" column to \"parent_category\"\n",
    "    columns_2[4] = 'sub_cat_level_1'\n",
    "    columns_2[5] = 'sub_cat_level_1_id'\n",
    "    columns_2[6] = 'sub_cat_level_2'\n",
    "    columns_2[7] = 'sub_cat_level_2_id'\n",
    "\n",
    "    df.columns = columns_2\n",
    "\n",
    "    # Explode the final childrens column\n",
    "\n",
    "    df = df.explode(\"children\").reset_index(drop=True)\n",
    "    df = pd.concat([df.drop([\"children\"], axis=1),\n",
    "                   df[\"children\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Remove completely NaN columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Column cleaning operations part 2 lol\n",
    "\n",
    "    columns_3 = df.columns.tolist()\n",
    "\n",
    "    # Rename first \"name\" column to \"parent_category\"\n",
    "    columns_3[8] = 'sub_cat_level_3'\n",
    "    columns_3[9] = 'sub_cat_level_3_id'\n",
    "\n",
    "    df.columns = columns_3\n",
    "\n",
    "    df = df.explode(\"children\").reset_index(drop=True)\n",
    "    df = pd.concat([df.drop([\"children\"], axis=1),\n",
    "                   df[\"children\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Remove completely NaN columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    columns_4 = df.columns.tolist()\n",
    "\n",
    "    # Rename first \"name\" column to \"parent_category\"\n",
    "    columns_4[10] = 'sub_cat_level_4'\n",
    "    columns_4[11] = 'sub_cat_level_4_id'\n",
    "\n",
    "    df.columns = columns_4\n",
    "\n",
    "    df['sub_cat_level_2_id'] = df['sub_cat_level_2_id'].astype('Int64')\n",
    "    df['sub_cat_level_3_id'] = df['sub_cat_level_3_id'].astype('Int64')\n",
    "    df['sub_cat_level_4_id'] = df['sub_cat_level_4_id'].astype('Int64')\n",
    "\n",
    "    df = df.fillna(pd.NA)\n",
    "\n",
    "    # Define a list of all subcategory columns\n",
    "    subcategory_columns = ['sub_cat_level_1', 'sub_cat_level_2',\n",
    "                           'sub_cat_level_3', 'sub_cat_level_4', 'parent_cat_desc']\n",
    "    subcategory_columns_id = ['sub_cat_level_1_id', 'sub_cat_level_2_id',\n",
    "                              'sub_cat_level_3_id', 'sub_cat_level_4_id', 'parent_cat_id']\n",
    "\n",
    "    # Coalesce the subcategory columns into a single column containing only the first non-null value\n",
    "    df['niche_desc'] = df[subcategory_columns].apply(\n",
    "        lambda x: x.dropna().iloc[0], axis=1)\n",
    "    df['niche_id'] = df[subcategory_columns_id].apply(\n",
    "        lambda x: x.dropna().iloc[0], axis=1)\n",
    "\n",
    "    df = df.drop(columns=['sub_cat_level_1', 'sub_cat_level_2',\n",
    "                 'sub_cat_level_3', 'sub_cat_level_4', 'parent_cat_desc'])\n",
    "    df = df.drop(columns=['sub_cat_level_1_id', 'sub_cat_level_2_id',\n",
    "                 'sub_cat_level_3_id', 'sub_cat_level_4_id', 'parent_cat_id'])\n",
    "    df = df.drop(columns=['metadata_name', 'metadata_id'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could replace top news with top tweets might be better content for the base source to summerize/ mutate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen Trending Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GoogleNews import GoogleNews\n",
    "from newspaper import Article, Config, ArticleException\n",
    "\n",
    "\n",
    "def fetch_top_stories(keyword, n):\n",
    "    # initialize GoogleNews object\n",
    "    googlenews = GoogleNews()\n",
    "    googlenews.set_lang('en')\n",
    "\n",
    "    # search for top news related to the keyword\n",
    "    googlenews.search(keyword)\n",
    "\n",
    "    # get URLs of top n stories\n",
    "    links = googlenews.get_links()[:n]\n",
    "\n",
    "    # initialize list to store dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # loop through URLs\n",
    "    for url in links:\n",
    "        # initialize Article object with custom configuration\n",
    "        config = Config()\n",
    "        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        article = Article(url, config=config)\n",
    "\n",
    "        try:\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            # check if summary is available\n",
    "            if article.summary:\n",
    "                summary = article.summary\n",
    "            else:\n",
    "                summary = None\n",
    "\n",
    "            # create dataframe with metadata and content\n",
    "            df = pd.DataFrame({\n",
    "                'title': [article.title],\n",
    "                'authors': [article.authors],\n",
    "                'publish_date': [article.publish_date],\n",
    "                'summary': [summary],\n",
    "                'content': [article.text],\n",
    "                'error': [None]\n",
    "            })\n",
    "\n",
    "        except ArticleException as e:\n",
    "            print(f\"Article {url} failed with error: {e}\")\n",
    "            # create dataframe with error message\n",
    "            df = pd.DataFrame({\n",
    "                'title': [None],\n",
    "                'authors': [None],\n",
    "                'publish_date': [None],\n",
    "                'summary': [None],\n",
    "                'content': [None],\n",
    "                'error': [f\"Article {url} failed with error: {e}\"]\n",
    "            })\n",
    "\n",
    "        # add dataframe to list\n",
    "        df_list.append(df)\n",
    "\n",
    "    # concatenate dataframes\n",
    "    result_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo code\n",
    "\n",
    "#Function\n",
    "# input: a search term string\n",
    "# output: a list of top trending youtube videos URLs related to that search term\n",
    "\n",
    "#Function\n",
    "# input: a list youtube urls\n",
    "# output: a data frame containing the following columns [url, is_clippable, peak_video_moments]\n",
    "\n",
    "#Function\n",
    "# input: a url of a youtube video\n",
    "# output: the file path which had the downloaded youtube video was written to as an .mp4\n",
    "\n",
    "#Function\n",
    "# input: file path to a mp4 file\n",
    "# output: the file path of the clipped video which was written as an .mp4\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pytube import YouTube\n",
    "import moviepy.editor as mp\n",
    "import re\n",
    "\n",
    "# Function to get top trending youtube videos URLs related to a search term\n",
    "def get_trending_videos(search_term):\n",
    "    # Use YouTube API to get search results for the given term\n",
    "    # Extract the video URLs from the search results\n",
    "    # Sort the URLs based on the view count and return the top URLs\n",
    "    # Return the list of top URLs\n",
    "    return top_urls\n",
    "\n",
    "# Function to get data frame containing [url, is_clippable, peak_video_moments] for a list of youtube urls\n",
    "def get_video_details(urls):\n",
    "    video_details = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Use pytube to get the video object\n",
    "            video = YouTube(url)\n",
    "            # Check if the video is clippable (duration less than 10 minutes)\n",
    "            is_clippable = True if video.length <= 600 else False\n",
    "            # Use moviepy to get peak moments of the video\n",
    "            clip = mp.VideoFileClip(video.filename)\n",
    "            peak_video_moments = clip.highlights()\n",
    "            # Append the details to the list\n",
    "            video_details.append([url, is_clippable, peak_video_moments])\n",
    "        except:\n",
    "            print(f\"Error occurred while processing URL: {url}\")\n",
    "    # Convert the list to a pandas data frame\n",
    "    video_df = pd.DataFrame(video_details, columns=['url', 'is_clippable', 'peak_video_moments'])\n",
    "    return video_df\n",
    "\n",
    "# Function to download a youtube video and return the file path of the downloaded .mp4 file\n",
    "def download_video(url):\n",
    "    try:\n",
    "        # Use pytube to get the video object and download the video\n",
    "        video = YouTube(url)\n",
    "        video_stream = video.streams.get_highest_resolution()\n",
    "        video_stream.download()\n",
    "        # Return the file path of the downloaded .mp4 file\n",
    "        return video.filename\n",
    "    except:\n",
    "        print(f\"Error occurred while downloading video from URL: {url}\")\n",
    "\n",
    "# Function to clip a video and return the file path of the clipped .mp4 file\n",
    "def clip_video(video_path):\n",
    "    try:\n",
    "        # Use moviepy to clip the video and save it to a new file\n",
    "        clip = mp.VideoFileClip(video_path)\n",
    "        clip = clip.subclip(0, 30) # clip the first 30 seconds of the video\n",
    "        clip_path = re.sub(\".mp4\", \"_clip.mp4\", video_path)\n",
    "        clip.write_videofile(clip_path)\n",
    "        # Return the file path of the clipped .mp4 file\n",
    "        return clip_path\n",
    "    except:\n",
    "        print(f\"Error occurred while clipping video: {video_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_short_text_prompt(title, content):\n",
    "    \"\"\"\n",
    "    Builds a string using the given title and content.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Replace all line breaks, carriage returns, and other non-alphanumeric characters with a space\n",
    "    cleaned_content = re.sub(r'[\\n\\r\\W]+', ' ', content)\n",
    "\n",
    "    # Remove any leading or trailing whitespace\n",
    "    cleaned_content = cleaned_content.strip()\n",
    "\n",
    "    output_string = f\"Find the 3 most interesting fact from the following article and condense them into a bulleted list containing as less than or equal to 9 words each:\\n {cleaned_content} \\n\"\n",
    "\n",
    "    return output_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ['open_ai_key']\n",
    "\n",
    "\n",
    "def generate_interesting_fact(prompt):\n",
    "    \"\"\"\n",
    "    Generates a text completion for the given prompt using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to generate a completion for.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    # Retrieve the generated completion\n",
    "    response_str = response.choices[0].message.content.strip()\n",
    "\n",
    "    return response_str\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_video_from_pexels(search_term, niche_name_clean):\n",
    "    # Make a request to the Pexels API to get videos based on the keyword\n",
    "    pexels_private_key = os.environ['pexels_api_key']\n",
    "    url = f'https://api.pexels.com/videos/search?query={search_term}&per_page=1'\n",
    "    headers = {'Authorization': 'k7D5HBnwo54elZXMc73DE4OiPUbYspcXwgMyNLWWpMyJHXe1AhTL0wcT'}\n",
    "    # headers = {'Authorization': pexels_private_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Get the URL of the video with the highest quality\n",
    "    video_url = response.json()['videos'][0]['video_files'][0]['link']\n",
    "\n",
    "    # Download the video\n",
    "    response = requests.get(video_url)\n",
    "\n",
    "    # Save the video to a file in the current working directory\n",
    "    filepath = f'data/video_example/{niche_name_clean}.mp4'\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = download_video_from_pexels('k - pop', 'anime_&_manga')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video & Audio | Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add search block here then download\n",
    "\n",
    "import requests\n",
    "\n",
    "# retruns first video id just for demo, could make more advanced search in the future\n",
    "\n",
    "\n",
    "def get_video_id(resource, api_key, expires, hmac, project_id, user_id, keywords, content_type):\n",
    "\n",
    "    url = f\"https://api.videoblocks.com{resource}?APIKEY={api_key}&EXPIRES={expires}&HMAC={hmac}&project_id={project_id}&user_id={user_id}&keywords={keywords}&content_type={content_type}\"\n",
    "    payload = {}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[\"results\"][0][\"id\"]\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_video_url(resource, api_key, expires, hmac, project_id, user_id):\n",
    "\n",
    "    url = f\"https://api.videoblocks.com{resource}?APIKEY={api_key}&EXPIRES={expires}&HMAC={hmac}&project_id={project_id}&user_id={user_id}\"\n",
    "    payload = {}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[\"MOV\"][\"_1080p\"]\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_video(url, filename):\n",
    "    # Create the data/video_example directory if it doesn't exist\n",
    "    os.makedirs('data/video_example', exist_ok=True)\n",
    "\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    download_path = 'data/video_example/' + filename\n",
    "    # Open a file for writing in the data/video_example directory\n",
    "    with open(download_path, 'wb') as f:\n",
    "        # Write the content of the response to the file\n",
    "        f.write(response.content)\n",
    "\n",
    "    return download_path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TikTokApi import TikTokApi\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "def get_tiktok_trending_audio(search_term, niche_name_clean, output_len=10):\n",
    "    # set up TikTok API client\n",
    "    api = TikTokApi()\n",
    "\n",
    "    # search for audio clips that match a keyword input\n",
    "    results = api.search_music(search_term, count=10)\n",
    "\n",
    "    # parse the API response and extract the first result's unique ID\n",
    "    if results:\n",
    "        music_id = results[0]['id']\n",
    "    else:\n",
    "        print(f\"No results found for keyword '{search_term}'\")\n",
    "        return None\n",
    "\n",
    "    # download the audio clip using its unique ID\n",
    "    try:\n",
    "        music_data = api.get_music_object(music_id)\n",
    "        music_url = music_data['playUrl']\n",
    "        music_file = api.get_bytes(music_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading music: {e}\")\n",
    "        return None\n",
    "\n",
    "    # extract the first output_len seconds of the audio clip\n",
    "    music = AudioFileClip(music_file)\n",
    "    music_extract = music.subclip(0, output_len)\n",
    "\n",
    "    # save the extracted audio clip to disk\n",
    "    output_file = f\"{niche_name_clean}.mp3\"\n",
    "    music_extract.write_audiofile(output_file)\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_path \u001b[39m=\u001b[39m get_tiktok_trending_audio(\n\u001b[1;32m      2\u001b[0m     search_term\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAnime & Manga\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m     niche_name_clean\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39manime_&_manga\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m     output_len\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m\n\u001b[1;32m      5\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mget_tiktok_trending_audio\u001b[0;34m(search_term, niche_name_clean, output_len)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tiktok_trending_audio\u001b[39m(search_term, niche_name_clean, output_len\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39m# set up TikTok API client\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     api \u001b[39m=\u001b[39m TikTokApi()\n\u001b[1;32m      8\u001b[0m     \u001b[39m# search for audio clips that match a keyword input\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     results \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39msearch_music(search_term, count\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m/workspace/automated-shorts/.venv/lib/python3.8/site-packages/TikTokApi/tiktok.py:159\u001b[0m, in \u001b[0;36mTikTokApi.__init__\u001b[0;34m(self, logging_level, request_delay, custom_device_id, generate_static_device_id, custom_verify_fp, use_test_endpoints, proxy, executable_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39msetLevel(logging_level)\n\u001b[1;32m    158\u001b[0m \u001b[39mwith\u001b[39;00m _thread_lock:\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(\n\u001b[1;32m    160\u001b[0m         request_delay\u001b[39m=\u001b[39;49mrequest_delay,\n\u001b[1;32m    161\u001b[0m         custom_device_id\u001b[39m=\u001b[39;49mcustom_device_id,\n\u001b[1;32m    162\u001b[0m         generate_static_device_id\u001b[39m=\u001b[39;49mgenerate_static_device_id,\n\u001b[1;32m    163\u001b[0m         custom_verify_fp\u001b[39m=\u001b[39;49mcustom_verify_fp,\n\u001b[1;32m    164\u001b[0m         use_test_endpoints\u001b[39m=\u001b[39;49muse_test_endpoints,\n\u001b[1;32m    165\u001b[0m         proxy\u001b[39m=\u001b[39;49mproxy,\n\u001b[1;32m    166\u001b[0m         executable_path\u001b[39m=\u001b[39;49mexecutable_path,\n\u001b[1;32m    167\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    168\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    169\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/automated-shorts/.venv/lib/python3.8/site-packages/TikTokApi/tiktok.py:205\u001b[0m, in \u001b[0;36mTikTokApi._initialize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_custom_device_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    201\u001b[0m         random\u001b[39m.\u001b[39mchoice(string\u001b[39m.\u001b[39mdigits) \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m19\u001b[39m)\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signer_url \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_browser \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mget_event_loop()\u001b[39m.\u001b[39;49mrun_until_complete(\n\u001b[1;32m    206\u001b[0m         asyncio\u001b[39m.\u001b[39;49mgather(browser\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    207\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user_agent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_browser\u001b[39m.\u001b[39muser_agent\n\u001b[1;32m    211\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/asyncio/base_events.py:592\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \n\u001b[1;32m    583\u001b[0m \u001b[39mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 592\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    594\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n\u001b[1;32m    595\u001b[0m future \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39mensure_future(future, loop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/asyncio/base_events.py:552\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 552\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    553\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "test_path = get_tiktok_trending_audio(\n",
    "    search_term='Anime & Manga', \n",
    "    niche_name_clean='anime_&_manga', \n",
    "    output_len=15\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio | download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to add section for play.ht api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add search block here then download\n",
    "\n",
    "import requests\n",
    "\n",
    "# retruns first video id just for demo, could make more advanced search in the future\n",
    "\n",
    "\n",
    "def get_audio_id(resource, api_key, expires, hmac, project_id, user_id, keywords, content_type):\n",
    "\n",
    "    url = f\"https://api.audioblocks.com{resource}?APIKEY={api_key}&EXPIRES={expires}&HMAC={hmac}&project_id={project_id}&user_id={user_id}&keywords={keywords}&content_type={content_type}\"\n",
    "    payload = {}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[\"results\"][0][\"id\"]\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_audio_url(resource, api_key, expires, hmac, project_id, user_id):\n",
    "\n",
    "    url = f\"https://api.audioblocks.com{resource}?APIKEY={api_key}&EXPIRES={expires}&HMAC={hmac}&project_id={project_id}&user_id={user_id}\"\n",
    "    payload = {}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['WAV']\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_audio(url, filename):\n",
    "    # Create the data/video_example directory if it doesn't exist\n",
    "    os.makedirs('data/video_example', exist_ok=True)\n",
    "\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    download_path = 'data/video_example/' + filename\n",
    "    # Open a file for writing in the data/video_example directory\n",
    "    with open(download_path, 'wb') as f:\n",
    "        # Write the content of the response to the file\n",
    "        f.write(response.content)\n",
    "\n",
    "    return download_path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video | Composite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video and audio text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, AudioFileClip\n",
    "\n",
    "# !cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
    "ImageMagickBinary = {\n",
    "    'magick': '/usr/bin/magick',\n",
    "    'convert': '/usr/bin/convert'\n",
    "}\n",
    "\n",
    "\n",
    "def create_composite(video_path, audio_path, text, font, fontsize, color, pos, output_path):\n",
    "    # Load the video file\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Load the audio file\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "\n",
    "    # Create the text clip\n",
    "    text_clip = TextClip(text, fontsize=fontsize, font=font, color=color)\n",
    "\n",
    "    # setting position of text in the center and duration will be 10 seconds \n",
    "    text_clip = text_clip.set_pos('center').set_duration(video_clip.duration)\n",
    "\n",
    "    audio_clip = audio_clip.set_duration(video_clip.duration)\n",
    "\n",
    "    # Combine the video clip, audio clip and text clip\n",
    "    final_clip = CompositeVideoClip([video_clip, text_clip]).set_audio(audio_clip)\n",
    "\n",
    "    # Write the video clip with the new text overlay and audio to a file\n",
    "    final_clip.write_videofile(\n",
    "        filename=output_path,\n",
    "        audio_codec='aac',\n",
    "        fps=48,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video and image, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, AudioFileClip\n",
    "\n",
    "# !cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
    "ImageMagickBinary = {\n",
    "'magick': '/usr/bin/magick',\n",
    "'convert': '/usr/bin/convert'\n",
    "}\n",
    "\n",
    "\n",
    "def create_composite(video_path, image_path, text, font, fontsize, color, pos, output_path):\n",
    "    # Load the video file\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Create the text clip\n",
    "    text_clip = TextClip(text, fontsize=fontsize, font=font, color=color)\n",
    "\n",
    "    # setting position of text in the center and duration will be 10 seconds \n",
    "    text_clip = text_clip.set_pos('center').set_duration(video_clip.duration)\n",
    "\n",
    "    # Load the image and video clips\n",
    "    image_clip = ImageClip(image_path).set_duration(video_clip.duration)\n",
    "\n",
    "    # Add the video clip in the bottom right corner of the image\n",
    "    video_clip = video_clip.resize(height=140)\n",
    "    video_clip = video_clip.set_position(('right', 'bottom'))\n",
    "\n",
    "    # Combine the clips and write the output file\n",
    "    final_clip = CompositeVideoClip([image_clip, text_clip, video_clip])\n",
    "\n",
    "    # Write the video clip with the new text overlay and audio to a file\n",
    "    final_clip.write_videofile(\n",
    "        filename=output_path,\n",
    "        audio_codec='aac',\n",
    "        fps=48,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video and video, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, AudioFileClip\n",
    "\n",
    "# !cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
    "ImageMagickBinary = {\n",
    "    'magick': '/usr/bin/magick',\n",
    "    'convert': '/usr/bin/convert'\n",
    "}\n",
    "\n",
    "\n",
    "def create_composite(video_path, background_video_path, text, font, fontsize, color, pos, output_path):\n",
    "    # Load the video files\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    background_clip = VideoFileClip(background_video_path)\n",
    "\n",
    "    # Create the text clip\n",
    "    text_clip = TextClip(text, fontsize=fontsize, font=font, color=color)\n",
    "\n",
    "    # Set position and duration of text to match the video clips\n",
    "    text_clip = text_clip.set_pos('center').set_duration(video_clip.duration)\n",
    "\n",
    "    # Trim the background clip to match the duration of the video clip\n",
    "    background_clip = background_clip.subclip(0, video_clip.duration)\n",
    "\n",
    "    # Resize the background clip to match the video clip dimensions\n",
    "    background_clip = background_clip.resize(video_clip.size)\n",
    "\n",
    "    # Add the video clip in the bottom right corner of the background clip\n",
    "    video_clip = video_clip.resize(height=140)\n",
    "    video_clip = video_clip.set_position(('right', 'bottom'))\n",
    "\n",
    "    # Combine the clips and write the output file\n",
    "    final_clip = CompositeVideoClip([background_clip, text_clip, video_clip])\n",
    "\n",
    "    # Write the video clip with the new text overlay and audio to a file\n",
    "    final_clip.write_videofile(\n",
    "        filename=output_path,\n",
    "        audio_codec='aac',\n",
    "        fps=48,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video data/video_example/output_test_digitar_v2.mp4.\n",
      "MoviePy - Writing audio in output_test_digitar_v2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video data/video_example/output_test_digitar_v2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready data/video_example/output_test_digitar_v2.mp4\n"
     ]
    }
   ],
   "source": [
    "create_composite(\n",
    "    video_path = 'data/video_example/digi_avatar_example_v2.mp4', \n",
    "    background_video_path = 'data/video_example/anime_&_manga.mp4',\n",
    "    text =  shorts_text_candidate, \n",
    "    font = \"DejaVu-Serif-Bold\", \n",
    "    fontsize = 15, \n",
    "    color = \"white\", \n",
    "    pos = None, \n",
    "    output_path = 'data/video_example/output_test_digitar_v2.mp4',\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_df = gen_niche_list()\n",
    "# niche_name = niche_df['niche_desc'][0]\n",
    "niche_name = \"K pop\"\n",
    "\n",
    "\n",
    "top_stories_df = fetch_top_stories(keyword=niche_name, n=5)\n",
    "title = top_stories_df['title'][0]\n",
    "content = top_stories_df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorts_prompt = build_short_text_prompt(\n",
    "    title=title,\n",
    "    content=content\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorts_text_candidate = generate_interesting_fact(\n",
    "    prompt=shorts_prompt[:1000],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Aespa is a fourth gen K-pop group\n",
      "- They will perform at an impressive location\n",
      "- They are the first in their generation to do so\n"
     ]
    }
   ],
   "source": [
    "print(shorts_text_candidate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute video grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required modules\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Provided by Storyblocks\n",
    "public_key = os.environ['storyblocks_api_key_public_test']\n",
    "private_key = os.environ['storyblocks_api_key_private_test']\n",
    "baseUrl = \"https://api.videoblocks.com\"\n",
    "expires = str(int(time.time()))\n",
    "resource = \"/api/v2/videos/search\"\n",
    "hmacBuilder = hmac.new(bytearray(private_key + expires, 'utf-8'),\n",
    "                       resource.encode('utf-8'), hashlib.sha256)\n",
    "hmacHex = hmacBuilder.hexdigest()\n",
    "project_id = \"auto_shorts_demo\"\n",
    "user_id = \"auto_shorts_bot_process\"\n",
    "keywords = niche_name\n",
    "content_type = \"footage\"\n",
    "\n",
    "\n",
    "video_id = get_video_id(\n",
    "    resource=resource,\n",
    "    api_key=public_key,\n",
    "    expires=expires,\n",
    "    hmac=hmacHex,\n",
    "    project_id=project_id,\n",
    "    user_id=user_id,\n",
    "    keywords=keywords,\n",
    "    content_type=content_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required modules\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Provided by Storyblocks\n",
    "public_key = os.environ['storyblocks_api_key_public_test']\n",
    "private_key = os.environ['storyblocks_api_key_private_test']\n",
    "baseUrl = \"https://api.videoblocks.com\"\n",
    "expires = str(int(time.time()))\n",
    "resource = f\"/api/v2/videos/stock-item/download/{video_id}\"\n",
    "hmacBuilder = hmac.new(bytearray(private_key + expires, 'utf-8'),\n",
    "                       resource.encode('utf-8'), hashlib.sha256)\n",
    "hmacHex = hmacBuilder.hexdigest()\n",
    "project_id = \"auto_shorts_demo\"\n",
    "user_id = \"auto_shorts_bot_process\"\n",
    "\n",
    "\n",
    "video_url = fetch_video_url(\n",
    "    resource=resource,\n",
    "    api_key=public_key,\n",
    "    expires=expires,\n",
    "    hmac=hmacHex,\n",
    "    project_id=project_id,\n",
    "    user_id=user_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_clean = niche_name.replace(' ', '_').lower()\n",
    "\n",
    "video_path = download_video(\n",
    "    url=video_url,\n",
    "    filename=f\"{niche_clean}_{video_id}.mp4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/video_example/arts_&_entertainment_5143986.mp4'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required modules\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# https://documentation.storyblocks.com/?_ga=2.209332763.846714940.1678072328-561796075.1674608327&_gac=1.252807931.1677039592.CjwKCAiA9NGfBhBvEiwAq5vSy4yIwO38LysWrZvL0h1E3otnsyv6YqT7i4aTe8HTwFTtCfnA08AymxoCTcsQAvD_BwE\n",
    "\n",
    "# Provided by Storyblocks\n",
    "public_key = os.environ['storyblocks_api_key_public_test']\n",
    "private_key = os.environ['storyblocks_api_key_private_test']\n",
    "baseUrl = \"https://api.audioblocks.com\"\n",
    "expires = str(int(time.time()))\n",
    "resource = \"/api/v2/audio/search\"\n",
    "hmacBuilder = hmac.new(bytearray(private_key + expires, 'utf-8'),\n",
    "                       resource.encode('utf-8'), hashlib.sha256)\n",
    "hmacHex = hmacBuilder.hexdigest()\n",
    "project_id = \"auto_shorts_demo\"\n",
    "user_id = \"auto_shorts_bot_process\"\n",
    "keywords = niche_name\n",
    "content_type = \"music\"\n",
    "\n",
    "\n",
    "audio_id = get_audio_id(\n",
    "    resource=resource,\n",
    "    api_key=public_key,\n",
    "    expires=expires,\n",
    "    hmac=hmacHex,\n",
    "    project_id=project_id,\n",
    "    user_id=user_id,\n",
    "    keywords=keywords,\n",
    "    content_type=content_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179496"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch audio urll\n",
    "\n",
    "# required modules\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Provided by Storyblocks\n",
    "public_key = os.environ['storyblocks_api_key_public_test']\n",
    "private_key = os.environ['storyblocks_api_key_private_test']\n",
    "baseUrl = \"https://api.audioblocks.com\"\n",
    "expires = str(int(time.time()))\n",
    "resource = f\"/api/v2/audio/stock-item/download/{audio_id}\"\n",
    "hmacBuilder = hmac.new(bytearray(private_key + expires, 'utf-8'),\n",
    "                       resource.encode('utf-8'), hashlib.sha256)\n",
    "hmacHex = hmacBuilder.hexdigest()\n",
    "project_id = \"auto_shorts_demo\"\n",
    "user_id = \"auto_shorts_bot_process\"\n",
    "\n",
    "\n",
    "audio_url = fetch_audio_url(\n",
    "    resource=resource,\n",
    "    api_key=public_key,\n",
    "    expires=expires,\n",
    "    hmac=hmacHex,\n",
    "    project_id=project_id,\n",
    "    user_id=user_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dm0qx8t0i9gc9.cloudfront.net/content/audio/HNxwBHlArk43bm5tw/audioblocks-robert-frost-iii_bright-happy-fun-jolly-v2_educational-full-mix-108-bpm_Svq1vspuw.wav?type=download&origin=AUDIOBLOCKS&timestamp_ms=1678075763429&publicKey=test_be5c923b8fca02fcc6a733ad883a8561ecfc2fff5b9c4365816124def58&apiVersion=2.0&endUserId=277b79e281cfc09f7571bb900689777fa2cd579d&projectId=auto_shorts_demo&stockItemId=179496&format=WAV&response-content-disposition=attachment&Expires=1678077563&Signature=Zz8DnuvZkVRq9tcK1zcEix5DCMUIr~EskaBdmT6ufRAGNwjAVEDJ6d0csVZBHOch3R11EJZecTlzj5TTIwPHYTkwAsI8Fgv-9h9GoQZeuLIJcft16u-6fuEsWo5QYeCSvK7oLYlQZGqwI4mEYl-0NbO-hI1rBDfcxQnQTBS5sc0artg1W1-wlO2SatgsP6dMStzrfI-MAfgRiLJcwfTVJwIVdQkZtc9PwI0t4ua7L-vqU1DYtAebtiBkwpKpG~R907rqn~pOr-Q9CcYhbb55PrPmBvFf6rOnjflFxIfn-elwix3u0s8BVmufneHSZ7MguonS3wzxcNvkexMU5Z9e7w__&Key-Pair-Id=APKAIAQ2JPZIIO2PHR7Q'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make the directory this all gets written to temporary and named base don the niche\n",
    "niche_clean = niche_name.replace(' ', '_').lower()\n",
    "\n",
    "audio_path = download_audio(\n",
    "    url=audio_url,\n",
    "    filename=f\"{niche_clean}_{audio_id}.wav\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video data/video_example/output_edit_example.mp4.\n",
      "MoviePy - Writing audio in output_edit_exampleTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video data/video_example/output_edit_example.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready data/video_example/output_edit_example.mp4\n"
     ]
    }
   ],
   "source": [
    "create_composite(\n",
    "    video_path = video_path, \n",
    "    audio_path = audio_path,\n",
    "    text =  f\"{title} \\n\\n {shorts_text_candidate}\", \n",
    "    font = \"DejaVu-Serif-Bold\", \n",
    "    fontsize = 35, \n",
    "    color = \"white\", \n",
    "    pos = None, \n",
    "    output_path = 'data/video_example/output_edit_example.mp4',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate affliate link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import hmac\n",
    "import urllib.parse\n",
    "import requests\n",
    "\n",
    "def generate_affiliate_link(input_str):\n",
    "    # Enter your Amazon API credentials\n",
    "    AWS_ACCESS_KEY = 'YOUR_AWS_ACCESS_KEY'\n",
    "    AWS_SECRET_KEY = 'YOUR_AWS_SECRET_KEY'\n",
    "    AWS_ASSOCIATE_TAG = 'YOUR_AWS_ASSOCIATE_TAG'\n",
    "\n",
    "    # Construct the API request\n",
    "    params = {\n",
    "        'Service': 'AWSECommerceService',\n",
    "        'Operation': 'ItemSearch',\n",
    "        'Keywords': input_str,\n",
    "        'AssociateTag': AWS_ASSOCIATE_TAG,\n",
    "        'ResponseGroup': 'ItemIds',\n",
    "        'SearchIndex': 'All'\n",
    "    }\n",
    "\n",
    "    # Construct the request URL\n",
    "    base_url = 'https://webservices.amazon.com/onca/xml'\n",
    "    query_string = urllib.parse.urlencode(sorted(params.items()))\n",
    "    request_url = f'{base_url}?{query_string}'\n",
    "\n",
    "    # Generate the signature for the request\n",
    "    message = f'GET\\nwebservices.amazon.com\\n/onca/xml\\n{query_string}'.encode('utf-8')\n",
    "    signature = hmac.new(AWS_SECRET_KEY.encode('utf-8'), message, hashlib.sha256).hexdigest()\n",
    "    request_url += f'&Signature={urllib.parse.quote(signature)}'\n",
    "\n",
    "    # Make the API request and parse the response\n",
    "    response = requests.get(request_url)\n",
    "    response_text = response.text\n",
    "\n",
    "    # Extract the item ID from the response\n",
    "    item_id = response_text.split('<ItemId>')[1].split('</ItemId>')[0]\n",
    "\n",
    "    # Construct the referral link using the item ID\n",
    "    referral_link = f'https://www.amazon.com/dp/{item_id}/?tag={AWS_ASSOCIATE_TAG}'\n",
    "\n",
    "    return referral_link\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload to all syndicated platforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Uploading file...\")? (1807360858.py, line 133)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 133\u001b[0;36m\u001b[0m\n\u001b[0;31m    print \"Uploading file...\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Uploading file...\")?\n"
     ]
    }
   ],
   "source": [
    "# https://developers.google.com/youtube/v3/guides/uploading_a_video\n",
    "\n",
    "# #!/usr/bin/python\n",
    "\n",
    "import httplib\n",
    "import httplib2\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from apiclient.http import MediaFileUpload\n",
    "from oauth2client.client import flow_from_clientsecrets\n",
    "from oauth2client.file import Storage\n",
    "from oauth2client.tools import argparser, run_flow\n",
    "\n",
    "\n",
    "# Explicitly tell the underlying HTTP transport library not to retry, since\n",
    "# we are handling retry logic ourselves.\n",
    "httplib2.RETRIES = 1\n",
    "\n",
    "# Maximum number of times to retry before giving up.\n",
    "MAX_RETRIES = 10\n",
    "\n",
    "# Always retry when these exceptions are raised.\n",
    "RETRIABLE_EXCEPTIONS = (httplib2.HttpLib2Error, IOError, httplib.NotConnected,\n",
    "  httplib.IncompleteRead, httplib.ImproperConnectionState,\n",
    "  httplib.CannotSendRequest, httplib.CannotSendHeader,\n",
    "  httplib.ResponseNotReady, httplib.BadStatusLine)\n",
    "\n",
    "# Always retry when an apiclient.errors.HttpError with one of these status\n",
    "# codes is raised.\n",
    "RETRIABLE_STATUS_CODES = [500, 502, 503, 504]\n",
    "\n",
    "# The CLIENT_SECRETS_FILE variable specifies the name of a file that contains\n",
    "# the OAuth 2.0 information for this application, including its client_id and\n",
    "# client_secret. You can acquire an OAuth 2.0 client ID and client secret from\n",
    "# the Google API Console at\n",
    "# https://console.cloud.google.com/.\n",
    "# Please ensure that you have enabled the YouTube Data API for your project.\n",
    "# For more information about using OAuth2 to access the YouTube Data API, see:\n",
    "#   https://developers.google.com/youtube/v3/guides/authentication\n",
    "# For more information about the client_secrets.json file format, see:\n",
    "#   https://developers.google.com/api-client-library/python/guide/aaa_client_secrets\n",
    "CLIENT_SECRETS_FILE = \"client_secrets.json\"\n",
    "\n",
    "# This OAuth 2.0 access scope allows an application to upload files to the\n",
    "# authenticated user's YouTube channel, but doesn't allow other types of access.\n",
    "YOUTUBE_UPLOAD_SCOPE = \"https://www.googleapis.com/auth/youtube.upload\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "# This variable defines a message to display if the CLIENT_SECRETS_FILE is\n",
    "# missing.\n",
    "MISSING_CLIENT_SECRETS_MESSAGE = \"\"\"\n",
    "WARNING: Please configure OAuth 2.0\n",
    "\n",
    "To make this sample run you will need to populate the client_secrets.json file\n",
    "found at:\n",
    "\n",
    "   %s\n",
    "\n",
    "with information from the API Console\n",
    "https://console.cloud.google.com/\n",
    "\n",
    "For more information about the client_secrets.json file format, please visit:\n",
    "https://developers.google.com/api-client-library/python/guide/aaa_client_secrets\n",
    "\"\"\" % os.path.abspath(os.path.join(os.path.dirname(__file__),\n",
    "                                   CLIENT_SECRETS_FILE))\n",
    "\n",
    "VALID_PRIVACY_STATUSES = (\"public\", \"private\", \"unlisted\")\n",
    "\n",
    "\n",
    "def get_authenticated_service(args):\n",
    "  flow = flow_from_clientsecrets(CLIENT_SECRETS_FILE,\n",
    "    scope=YOUTUBE_UPLOAD_SCOPE,\n",
    "    message=MISSING_CLIENT_SECRETS_MESSAGE)\n",
    "\n",
    "  storage = Storage(\"%s-oauth2.json\" % sys.argv[0])\n",
    "  credentials = storage.get()\n",
    "\n",
    "  if credentials is None or credentials.invalid:\n",
    "    credentials = run_flow(flow, storage, args)\n",
    "\n",
    "  return build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    http=credentials.authorize(httplib2.Http()))\n",
    "\n",
    "def initialize_upload(youtube, options):\n",
    "  tags = None\n",
    "  if options.keywords:\n",
    "    tags = options.keywords.split(\",\")\n",
    "\n",
    "  body=dict(\n",
    "    snippet=dict(\n",
    "      title=options.title,\n",
    "      description=options.description,\n",
    "      tags=tags,\n",
    "      categoryId=options.category\n",
    "    ),\n",
    "    status=dict(\n",
    "      privacyStatus=options.privacyStatus\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Call the API's videos.insert method to create and upload the video.\n",
    "  insert_request = youtube.videos().insert(\n",
    "    part=\",\".join(body.keys()),\n",
    "    body=body,\n",
    "    # The chunksize parameter specifies the size of each chunk of data, in\n",
    "    # bytes, that will be uploaded at a time. Set a higher value for\n",
    "    # reliable connections as fewer chunks lead to faster uploads. Set a lower\n",
    "    # value for better recovery on less reliable connections.\n",
    "    #\n",
    "    # Setting \"chunksize\" equal to -1 in the code below means that the entire\n",
    "    # file will be uploaded in a single HTTP request. (If the upload fails,\n",
    "    # it will still be retried where it left off.) This is usually a best\n",
    "    # practice, but if you're using Python older than 2.6 or if you're\n",
    "    # running on App Engine, you should set the chunksize to something like\n",
    "    # 1024 * 1024 (1 megabyte).\n",
    "    media_body=MediaFileUpload(options.file, chunksize=-1, resumable=True)\n",
    "  )\n",
    "\n",
    "  resumable_upload(insert_request)\n",
    "\n",
    "# This method implements an exponential backoff strategy to resume a\n",
    "# failed upload.\n",
    "def resumable_upload(insert_request):\n",
    "  response = None\n",
    "  error = None\n",
    "  retry = 0\n",
    "  while response is None:\n",
    "    try:\n",
    "      print \"Uploading file...\"\n",
    "      status, response = insert_request.next_chunk()\n",
    "      if response is not None:\n",
    "        if 'id' in response:\n",
    "          print \"Video id '%s' was successfully uploaded.\" % response['id']\n",
    "        else:\n",
    "          exit(\"The upload failed with an unexpected response: %s\" % response)\n",
    "    except HttpError, e:\n",
    "      if e.resp.status in RETRIABLE_STATUS_CODES:\n",
    "        error = \"A retriable HTTP error %d occurred:\\n%s\" % (e.resp.status,\n",
    "                                                             e.content)\n",
    "      else:\n",
    "        raise\n",
    "    except RETRIABLE_EXCEPTIONS, e:\n",
    "      error = \"A retriable error occurred: %s\" % e\n",
    "\n",
    "    if error is not None:\n",
    "      print error\n",
    "      retry += 1\n",
    "      if retry > MAX_RETRIES:\n",
    "        exit(\"No longer attempting to retry.\")\n",
    "\n",
    "      max_sleep = 2 ** retry\n",
    "      sleep_seconds = random.random() * max_sleep\n",
    "      print \"Sleeping %f seconds and then retrying...\" % sleep_seconds\n",
    "      time.sleep(sleep_seconds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  argparser.add_argument(\"--file\", required=True, help=\"Video file to upload\")\n",
    "  argparser.add_argument(\"--title\", help=\"Video title\", default=\"Test Title\")\n",
    "  argparser.add_argument(\"--description\", help=\"Video description\",\n",
    "    default=\"Test Description\")\n",
    "  argparser.add_argument(\"--category\", default=\"22\",\n",
    "    help=\"Numeric video category. \" +\n",
    "      \"See https://developers.google.com/youtube/v3/docs/videoCategories/list\")\n",
    "  argparser.add_argument(\"--keywords\", help=\"Video keywords, comma separated\",\n",
    "    default=\"\")\n",
    "  argparser.add_argument(\"--privacyStatus\", choices=VALID_PRIVACY_STATUSES,\n",
    "    default=VALID_PRIVACY_STATUSES[0], help=\"Video privacy status.\")\n",
    "  args = argparser.parse_args()\n",
    "\n",
    "  if not os.path.exists(args.file):\n",
    "    exit(\"Please specify a valid file using the --file= parameter.\")\n",
    "\n",
    "  youtube = get_authenticated_service(args)\n",
    "  try:\n",
    "    initialize_upload(youtube, args)\n",
    "  except HttpError, e:\n",
    "    print \"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affliant links api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.affluent.io/reference/post_v1-actions-1\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://server-api.affluent.io/v1/actions/\"\n",
    "\n",
    "payload = {\n",
    "    \"currency\": \"USD\",\n",
    "    \"firstDayOfWeek\": 1,\n",
    "    \"limit\": 100,\n",
    "    \"offset\": 0,\n",
    "    \"includeSkus\": \"false\"\n",
    "}\n",
    "headers = {\n",
    "    \"accept\": \"application/stream+json\",\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ['open_ai_key']\n",
    "\n",
    "\n",
    "def generate_bullet_summary(prompt, max_tokens_param):\n",
    "    \"\"\"\n",
    "    Generates a text completion for the given prompt using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to generate a completion for.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    # Set up the API parameters\n",
    "    model_engine = \"text-davinci-003\"  # Replace with your desired language model\n",
    "    max_tokens = max_tokens_param  # Maximum number of tokens to generate\n",
    "    n = 1  # Number of completions to generate\n",
    "    stop_sequence = None  # Sequence to stop generation at\n",
    "\n",
    "    # Generate the completion using the OpenAI API\n",
    "    response = openai.Completion.create(\n",
    "        model=model_engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        n=n,\n",
    "        stop=stop_sequence,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    # Retrieve the generated completion\n",
    "    response_str = response.choices[0].text.strip()\n",
    "\n",
    "    return response_str\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c77b7e94866499183660717fc6b5e93d99962d40af9cbd2a4f143d796876e246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
